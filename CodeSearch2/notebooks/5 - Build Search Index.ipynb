{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "You should have completed steps 1-4 of this tutorial before beginning this exercise.  The files required for this notebook are generated by those previous steps.\n",
    "\n",
    "Creating the search engine for this example is extremely CPU and memory intensive.  We used an an AWS `x1.32xlarge` instance (128 cores) in order to achieve the maximum speed with building the search index. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import nmslib\n",
    "from lang_model_utils import load_lm_vocab, Query2Emb\n",
    "from general_utils import create_nmslib_search_index\n",
    "\n",
    "input_path = Path('./data/processed_data/')\n",
    "code2emb_path = Path('./data/code2emb/')\n",
    "output_path = Path('./data/search')\n",
    "output_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Metadata\n",
    "\n",
    "We will want to organize the data that we will want to display for the search results, which will be:\n",
    "\n",
    "1. The original code\n",
    "2. A link to the original code\n",
    "\n",
    "For convenience, we will collect this data into a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>function _interopRequireDefault(obj) { return ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>function extern(k, i) {\\n        return k + i;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>function (mod) {\\n    t.is(mod.instance.export...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>function (mod) {\\n    t.is(mod.instance.export...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>function () {\\n    return (0, _.compile)('func...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url                                               code\n",
       "0    0  function _interopRequireDefault(obj) { return ...\n",
       "1    1  function extern(k, i) {\\n        return k + i;...\n",
       "2    2  function (mod) {\\n    t.is(mod.instance.export...\n",
       "3    3  function (mod) {\\n    t.is(mod.instance.export...\n",
       "4    4  function () {\\n    return (0, _.compile)('func..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read original code\n",
    "code_df = pd.read_json(input_path/'without_docstrings_original_function.json.gz')\n",
    "code_df.columns = ['code']\n",
    "\n",
    "# read file of urls\n",
    "url_df = pd.DataFrame([i for i in range(code_df.shape[0])])\n",
    "url_df.columns = ['url']\n",
    "                       \n",
    "# make sure these files have same number of rows\n",
    "assert code_df.shape[0] == url_df.shape[0]\n",
    "\n",
    "# collect these two together into a dataframe\n",
    "ref_df = pd.concat([url_df, code_df], axis = 1).reset_index(drop=True)\n",
    "ref_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference the above files are also available for download incase you skipped step 1:\n",
    "\n",
    "`without_docstrings.lineage`: https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings.lineage\n",
    "\n",
    "`without_docstrings_original_function.json.gz`: https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings_original_function.json.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Search Index For Vectorized Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First read in the vectorized code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodoc_vecs = np.load(code2emb_path/'nodoc_vecs.npy')\n",
    "assert nodoc_vecs.shape[0] == ref_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the search index. **Warning:** this step takes ~ 18 minutes on an `x1.32xlarge` instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 8min 19s, sys: 1min 10s, total: 1h 9min 30s\n",
      "Wall time: 8min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "search_index = create_nmslib_search_index(nodoc_vecs)\n",
    "search_index.saveIndex('./data/search/search_index.nmslib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This cached version of this index can be downloaded here:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create A Minimal Search Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the cached version of the required files on google cloud:\n",
    "\n",
    "`lang_model_cpu_v2.torch`: https://storage.googleapis.com/kubeflow-examples/code_search/data/lang_model/lang_model_cpu_v2.torch\n",
    "\n",
    "`vocab_v2.cls`: https://storage.googleapis.com/kubeflow-examples/code_search/data/lang_model/vocab_v2.cls\n",
    "\n",
    "`search_index.nmslib`: https://storage.googleapis.com/kubeflow-examples/code_search/data/search/search_index.nmslib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Loaded vocab of size 8,078\n"
     ]
    }
   ],
   "source": [
    "lang_model = torch.load('./data/lang_model/lang_model_cpu_v2.torch', \n",
    "                        map_location=lambda storage, loc: storage)\n",
    "\n",
    "vocab = load_lm_vocab('./data/lang_model/vocab_v2.cls')\n",
    "q2emb = Query2Emb(lang_model = lang_model.cpu(),\n",
    "                  vocab = vocab)\n",
    "\n",
    "search_index = nmslib.init(method='hnsw', space='cosinesimil')\n",
    "search_index.loadIndex('./data/search/search_index.nmslib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Query2Emb` is a helper class that will vectorize sentences using the language model trained in Part 3.  \n",
    "\n",
    "In this case, we call the method `emb_mean` because we are taking the mean over the time steps of the hidden states in order to construct a sentence embedding for the query supplied by the user.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processing 1 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 500)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = q2emb.emb_mean('Hello World!  This is a test.')\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an object to make the process of showing search results easier\n",
    "\n",
    "The below object organizes all the pieces together for searching the index and displaying the results with a method call.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class search_engine:\n",
    "    \"\"\"Organizes all the necessary elements we need to make a search engine.\"\"\"\n",
    "    def __init__(self, \n",
    "                 nmslib_index, \n",
    "                 ref_df, \n",
    "                 query2emb_func):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ==========\n",
    "        nmslib_index : nmslib object\n",
    "            This is pre-computed search index.\n",
    "        ref_df : pandas.DataFrame\n",
    "            This dataframe contains meta-data for search results, \n",
    "            must contain the columns 'code' and 'url'.\n",
    "        query2emb_func : callable\n",
    "            This is a function that takes as input a string and returns a vector\n",
    "            that is in the same vector space as what is loaded into the search index.\n",
    "\n",
    "        \"\"\"\n",
    "        assert 'url' in ref_df.columns\n",
    "        assert 'code' in ref_df.columns\n",
    "        \n",
    "        self.search_index = nmslib_index\n",
    "        self.ref_df = ref_df\n",
    "        self.query2emb_func = query2emb_func\n",
    "    \n",
    "    def search(self, str_search, k=2):\n",
    "        \"\"\"\n",
    "        Prints the code that are the nearest neighbors (by cosine distance)\n",
    "        to the search query.\n",
    "        \n",
    "        Parameters\n",
    "        ==========\n",
    "        str_search : str\n",
    "            a search query.  Ex: \"read data into pandas dataframe\"\n",
    "        k : int\n",
    "            the number of nearest neighbors to return.  Defaults to 2.\n",
    "        \n",
    "        \"\"\"\n",
    "        query = self.query2emb_func(str_search)\n",
    "        idxs, dists = self.search_index.knnQuery(query, k=k)\n",
    "        \n",
    "        for idx, dist in zip(idxs, dists):\n",
    "            code = self.ref_df.iloc[idx].code\n",
    "            url = self.ref_df.iloc[idx].url\n",
    "            print(f'cosine dist:{dist:.4f}  url: {url}\\n---------------\\n')\n",
    "            print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "se = search_engine(nmslib_index=search_index,\n",
    "                   ref_df=ref_df,\n",
    "                   query2emb_func=q2emb.emb_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Some Queries Against The Index!!\n",
    "\n",
    "Now that we have instantiated the search engine, we can use the `search` method to display the results.\n",
    "\n",
    "**Warning:** some of the displayed links may not work since this is historical data retrieved from a [historical open dataset Google has hosted on BigQuery](https://cloud.google.com/bigquery/public-data/github)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Processing 1 rows\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine dist:0.3501  url: 502247\n",
      "---------------\n",
      "\n",
      "function (match) {\n",
      "    if (typeof _entitiesencode2.default[match] !== 'undefined') {\n",
      "      return _entitiesencode2.default[match];\n",
      "    }\n",
      "    return match;\n",
      "  }\n",
      "cosine dist:0.3555  url: 451291\n",
      "---------------\n",
      "\n",
      "function (re) {\n",
      "    var index = this.tail.search(re),\n",
      "        match;switch (index) {case -1:\n",
      "        match = this.tail;this.tail = \"\";break;case 0:\n",
      "        match = \"\";break;default:\n",
      "        match = this.tail.substring(0, index);this.tail = this.tail.substring(index);}this.pos += match.length;return match;\n",
      "  }\n"
     ]
    }
   ],
   "source": [
    "se.search('replace substring')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Custom Ipython Magic Function To Create A Fake Search Box\n",
    "\n",
    "You don't know how to build a website?  No problem!  You can still impress your friends by using a [custom magic function](https://ipython.org/ipython-doc/3/config/custommagics.html) to allow you to do a live demonstration in a Jupyter notebook.  This is what I did when I first created this prototype!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import (register_line_magic, register_cell_magic,\n",
    "                                register_line_cell_magic)\n",
    "@register_cell_magic\n",
    "def search(line, cell):\n",
    "    return se.search(cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Live Semantic Search of Code (Searching Holdout Set Only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: %%search is a cell magic, but the cell body is empty.\n"
     ]
    }
   ],
   "source": [
    "%%search \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
