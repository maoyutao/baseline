{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "You should have completed steps 1-3 of this tutorial before beginning this exercise.  The files required for this notebook are generated by those previous steps.\n",
    "\n",
    "This notebook takes approximately 3 hours to run on an AWS `p3.8xlarge` instance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Optional: you can set what GPU you want to use in a notebook like this.  \n",
    "# # Useful if you want to run concurrent experiments at the same time on different GPUs.\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from seq2seq_utils import extract_encoder_model, load_encoder_inputs\n",
    "from keras.layers import Input, Dense, BatchNormalization, Dropout, Lambda\n",
    "\n",
    "from keras.models import load_model, Model\n",
    "from seq2seq_utils import load_text_processor\n",
    "\n",
    "#where you will save artifacts from this step\n",
    "OUTPUT_PATH = Path('./data/code2emb/')\n",
    "OUTPUT_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "# These are where the artifacts are stored from steps 2 and 3, respectively.\n",
    "seq2seq_path = Path('./data/seq2seq/')\n",
    "langemb_path = Path('./data/lang_model_emb/')\n",
    "\n",
    "# set seeds\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Model That Maps Code To Sentence Embedding Space\n",
    "\n",
    "In step 2, we trained a seq2seq model that can summarize function code using `(code, docstring)` pairs as the training data.  \n",
    "\n",
    "In this step, we will fine tune the encoder from the seq2seq model to generate code embeddings in the docstring space by using `(code, docstring-embeddings)` as the training data.  Therefore, this notebook will go through the following steps:\n",
    "\n",
    "1. Load the seq2seq model and extract the encoder (remember seq2seq models have an encoder and a decoder).\n",
    "2. Freeze the weights of the encoder.\n",
    "3. Add some dense layers on top of the encoder.\n",
    "4. Train this new model supplying by supplying `(code, docstring-embeddings)` pairs.  We will call this model `code2emb_model`.\n",
    "5. Unfreeze the entire model, and resume training.  This helps fine tune the model a little more towards this task.\n",
    "6. Encode all of the code, including code that does not contain a docstring and save that into a search index for future use.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load seq2seq model from Step 2 and extract the encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First load the seq2seq model from Step2, then extract the encoder (we do not need the decoder)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of encoder input: (244125, 55)\n"
     ]
    }
   ],
   "source": [
    "# load the pre-processed data for the encoder (we don't care about the decoder in this step)\n",
    "encoder_input_data, doc_length = load_encoder_inputs(seq2seq_path/'py_t_code_vecs_v2.npy')\n",
    "seq2seq_Model = load_model(seq2seq_path/'code_summary_seq2seq_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder-Input (InputLayer)   (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "Body-Word-Embedding (Embeddi (None, 55, 800)           16001600  \n",
      "_________________________________________________________________\n",
      "Encoder-Batchnorm-1 (BatchNo (None, 55, 800)           3200      \n",
      "_________________________________________________________________\n",
      "Encoder-Last-GRU (GRU)       [(None, 1000), (None, 100 5403000   \n",
      "=================================================================\n",
      "Total params: 21,407,800\n",
      "Trainable params: 21,406,200\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Extract Encoder from seq2seq model\n",
    "encoder_model = extract_encoder_model(seq2seq_Model)\n",
    "# Get a summary of the encoder and its layers\n",
    "encoder_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f305369bb00> False\n",
      "<keras.layers.embeddings.Embedding object at 0x7f305369beb8> False\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f305369b9e8> False\n",
      "<keras.layers.recurrent.GRU object at 0x7f305369ba58> False\n"
     ]
    }
   ],
   "source": [
    "# Freeze Encoder Model\n",
    "for l in encoder_model.layers:\n",
    "    l.trainable = False\n",
    "    print(l, l.trainable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Docstring Embeddings From From Step 3\n",
    "\n",
    "The target for our `code2emb` model will be docstring-embeddings instead of docstrings.  Therefore, we will use the embeddings for docstrings that we computed in step 3.  For this tutorial, we will use the average over all hidden states, which is saved in the file `avg_emb_dim500_v2.npy`.\n",
    "\n",
    "Note that in our experiments, a concatenation of the average, max, and last hidden state worked better than using the average alone.  However, in the interest of simplicity we demonstrate just using the average hidden state.  We leave it as an exercise to the reader to experiment with other approaches. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244125 244125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(244125, 500)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Fitlam Embeddings\n",
    "fastailm_emb = np.load(langemb_path/'trn_avg_emb_dim500_v2.npy')\n",
    "print(encoder_input_data.shape[0], fastailm_emb.shape[0])\n",
    "# check that the encoder inputs have the same number of rows as the docstring embeddings\n",
    "assert encoder_input_data.shape[0] == fastailm_emb.shape[0]\n",
    "\n",
    "fastailm_emb.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct `code2emb` Model Architecture\n",
    "\n",
    "The `code2emb` model is the encoder from the seq2seq model with some dense layers added on top.  The output of the last dense layer of this model needs to match the dimensionality of the docstring embedding, which is 500 in this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Encoder Model ####\n",
    "encoder_inputs = Input(shape=(doc_length,), name='Encoder-Input')\n",
    "enc_out = encoder_model(encoder_inputs)\n",
    "\n",
    "# first dense layer with batch norm\n",
    "x = Dense(500, activation='relu')(enc_out)\n",
    "x = BatchNormalization(name='bn-1')(x)\n",
    "out = Dense(500)(x)\n",
    "code2emb_model = Model([encoder_inputs], out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Encoder-Input (InputLayer)   (None, 55)                0         \n",
      "_________________________________________________________________\n",
      "Encoder-Model (Model)        (None, 1000)              21407800  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "bn-1 (BatchNormalization)    (None, 500)               2000      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "=================================================================\n",
      "Total params: 22,160,800\n",
      "Trainable params: 752,000\n",
      "Non-trainable params: 21,408,800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "code2emb_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the `code2emb` Model\n",
    "\n",
    "The model we are training is relatively simple - with two dense layers on top of the pre-trained encoder.  We are leaving the encoder frozen at first, then will unfreeze the encoder in a later step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/opt/conda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192, got 176\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import Callback\n",
    "import json\n",
    "from pathlib import Path\n",
    "from seq2seq_utils import load_text_processor\n",
    "from general_utils import create_nmslib_search_index\n",
    "from lang_model_utils import load_lm_vocab, Query2Emb\n",
    "import torch\n",
    "\n",
    "seq2seq_path = Path('./data/seq2seq/')\n",
    "threshold =1\n",
    "\n",
    "class EvaluateCode2Emd(Callback):\n",
    "    def evaluate(self):\n",
    "        with open('validation_set_js.json', 'r') as f:\n",
    "#             [query, code, isPositive]\n",
    "            valid_pairs = json.load(f)\n",
    "        all = 0\n",
    "        find = 0\n",
    "        num_encoder_tokens, enc_pp = load_text_processor(seq2seq_path/'py_code_proc_v2.dpkl')\n",
    "        lang_model = torch.load('./data/lang_model/lang_model_cpu_v2.torch', \n",
    "                            map_location=lambda storage, loc: storage)\n",
    "        vocab = load_lm_vocab('./data/lang_model/vocab_v2.cls')\n",
    "        q2emb = Query2Emb(lang_model = lang_model.cpu(), vocab = vocab).emb_mean\n",
    "        i=0\n",
    "        for pair in valid_pairs:\n",
    "            lang_model.reset()\n",
    "    #       code 2 emb\n",
    "            encinp = enc_pp.transform([pair['result']['code']])\n",
    "            nodoc_vecs = self.model.predict(encinp, batch_size=1)\n",
    "            search_index = create_nmslib_search_index(nodoc_vecs)\n",
    "    #       query 2 emb  \n",
    "            query = q2emb(pair['query'])\n",
    "#             search\n",
    "            idxs, dists = search_index.knnQuery(query, k=1)\n",
    "            if dists[0] < threshold:\n",
    "                find += 1\n",
    "            all += 1\n",
    "        assert all > 0\n",
    "        return find/all\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        coverage = self.evaluate()\n",
    "        print('epoch:', epoch, 'coverage:', coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "244125/244125 [==============================] - 100s 409us/step - loss: -0.7435\n",
      "Epoch 2/16\n",
      "244125/244125 [==============================] - 99s 406us/step - loss: -0.7532\n",
      "Epoch 3/16\n",
      "244125/244125 [==============================] - 99s 407us/step - loss: -0.7564\n",
      "Epoch 4/16\n",
      "244125/244125 [==============================] - 100s 408us/step - loss: -0.7584\n",
      "Epoch 5/16\n",
      "244125/244125 [==============================] - 100s 409us/step - loss: -0.7606\n",
      "Epoch 6/16\n",
      "244125/244125 [==============================] - 100s 410us/step - loss: -0.7621\n",
      "Epoch 7/16\n",
      "244125/244125 [==============================] - 100s 411us/step - loss: -0.7632\n",
      "Epoch 8/16\n",
      "244125/244125 [==============================] - 100s 411us/step - loss: -0.7643\n",
      "Epoch 9/16\n",
      "244125/244125 [==============================] - 100s 411us/step - loss: -0.7648\n",
      "Epoch 10/16\n",
      "244125/244125 [==============================] - 101s 412us/step - loss: -0.7656\n",
      "Epoch 11/16\n",
      "244125/244125 [==============================] - 100s 412us/step - loss: -0.7664\n",
      "Epoch 12/16\n",
      "244125/244125 [==============================] - 100s 411us/step - loss: -0.7670\n",
      "Epoch 13/16\n",
      "244125/244125 [==============================] - 101s 412us/step - loss: -0.7677\n",
      "Epoch 14/16\n",
      "244125/244125 [==============================] - 100s 412us/step - loss: -0.7683\n",
      "Epoch 15/16\n",
      "244125/244125 [==============================] - 100s 412us/step - loss: -0.7687\n",
      "Epoch 16/16\n",
      "244125/244125 [==============================] - 101s 412us/step - loss: -0.7683\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint\n",
    "from keras import optimizers\n",
    "\n",
    "code2emb_model.compile(optimizer=optimizers.Nadam(lr=0.002), loss='cosine_proximity')\n",
    "script_name_base = 'code2emb_model_'\n",
    "csv_logger = CSVLogger('{:}.log'.format(script_name_base))\n",
    "model_checkpoint = ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),\n",
    "                                   save_best_only=True)\n",
    "evaluater = EvaluateCode2Emd()\n",
    "batch_size = 2000\n",
    "epochs = 16\n",
    "history = code2emb_model.fit([encoder_input_data], fastailm_emb,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`.7453`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unfreeze all Layers of Model and Resume Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous step, we left the encoder frozen.  Now that the dense layers are trained, we will unfreeze the entire model and let it train some more.  This will hopefully allow this model to specialize on this task a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.input_layer.InputLayer object at 0x7f305ea3d5f8> True\n",
      "<keras.engine.training.Model object at 0x7f305376a400> True\n",
      "<keras.layers.core.Dense object at 0x7f305ea3d710> True\n",
      "<keras.layers.normalization.BatchNormalization object at 0x7f305ea3da90> True\n",
      "<keras.layers.core.Dense object at 0x7f3055949940> True\n"
     ]
    }
   ],
   "source": [
    "for l in code2emb_model.layers:\n",
    "    l.trainable = True\n",
    "    print(l, l.trainable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 214830 samples, validate on 29295 samples\n",
      "Epoch 17/20\n",
      "214830/214830 [==============================] - 98s 458us/step - loss: -0.7712 - val_loss: -0.7806\n",
      "Epoch 18/20\n",
      "214830/214830 [==============================] - 97s 451us/step - loss: -0.7713 - val_loss: -0.7807\n",
      "Epoch 19/20\n",
      "214830/214830 [==============================] - 97s 454us/step - loss: -0.7713 - val_loss: -0.7808\n",
      "Epoch 20/20\n",
      "214830/214830 [==============================] - 98s 456us/step - loss: -0.7713 - val_loss: -0.7807\n"
     ]
    }
   ],
   "source": [
    "code2emb_model.compile(optimizer=optimizers.Nadam(lr=0.0001), loss='cosine_proximity')\n",
    "script_name_base = 'code2emb_model_unfreeze_'\n",
    "csv_logger = CSVLogger('{:}.log'.format(script_name_base))\n",
    "model_checkpoint = ModelCheckpoint('{:}.epoch{{epoch:02d}}-val{{val_loss:.5f}}.hdf5'.format(script_name_base),\n",
    "                                   save_best_only=True)\n",
    "evaluater = EvaluateCode2Emd()\n",
    "batch_size = 2000\n",
    "epochs = 20\n",
    "history = code2emb_model.fit([encoder_input_data], fastailm_emb,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          initial_epoch=16,\n",
    "          validation_split=0.12, callbacks=[csv_logger, model_checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save `code2emb` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2emb_model.save(OUTPUT_PATH/'code2emb_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file has been cached and is also available for download here:\n",
    "\n",
    "`code2emb_model.hdf5`:https://storage.googleapis.com/kubeflow-examples/code_search/data/code2emb/code2emb_model.hdf5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize all of the code without docstrings\n",
    "\n",
    "We want to vectorize all of the code without docstrings so we can test the efficacy of the search on the code that was never seen by the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from seq2seq_utils import load_text_processor\n",
    "code2emb_path = Path('./data/code2emb/')\n",
    "seq2seq_path = Path('./data/seq2seq/')\n",
    "data_path = Path('./data/processed_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of vocabulary for data/seq2seq/py_code_proc_v2.dpkl: 20,002\n"
     ]
    }
   ],
   "source": [
    "code2emb_model = load_model(code2emb_path/'code2emb_model.hdf5')\n",
    "num_encoder_tokens, enc_pp = load_text_processor(seq2seq_path/'py_code_proc_v2.dpkl')\n",
    "\n",
    "with open(data_path/'without_docstrings.function', 'r') as f:\n",
    "    no_docstring_funcs = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(data_path/'train.function', 'r') as f:\n",
    "    train_funcs = f.readlines()\n",
    "with open(data_path/'valid.function', 'r') as f:\n",
    "    valid_funcs = f.readlines()\n",
    "with open(data_path/'test.function', 'r') as f:\n",
    "    test_funcs = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_funcs = no_docstring_funcs + train_funcs + valid_funcs + test_funcs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-process code without docstrings for input into `code2emb` model\n",
    "\n",
    "We use the same transformer we used to train the original model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['function _interopRequireDefault obj return obj obj __esModule obj default obj\\n',\n",
       " 'function t var walt n import extern Add from env n type Add i32 i32 0 i32 n function add x i32 y i32 1 i32 n return x y n n n export function test i32 n const x i32 add 2 n const y i32 extern 1 0 n return x y n return WebAssembly instantiate 0 _ compile walt buffer env extern function extern k i return k i\\n',\n",
       " 'function mod t is mod instance exports test 4\\n',\n",
       " 'function t var walt n shadowing variables should be OK n export function test i32 n Definiong an identifier which is a function name n const test i32 42 n n The function pointer parser should defer to available scopes first and n not re map this identifier to a pointer n return test n n return WebAssembly instantiate 0 _ compile walt buffer then function mod t is mod instance exports test 42\\n',\n",
       " 'function t var src n For pointers n const table Table element anyfunc initial 10 max 10 n For object operations n const memory Memory initial 1 n n type Test i32 n type Type a i32 n n const x i32 32 n n function callback pointer Test i32 return pointer n function result i32 return 2 n function addOne ptr Type ptr a 1 n n export function testParams x i32 y i32 i32 return x y n export function testGlobalScope i32 let x i32 42 return x n This just needs to compile n export function testUninitializedLocals let x i32 n This also tests built in words in function names void n export function testVoidIsOptional n export function test0FunctionNames1 i32 return 2 n export function testPointerArguments i32 n let original Type 0 n original a 4 n addOne original n return original a n n export function testFunctionPointers i32 n return callback result callback result n n n function addArray arr i32 x i32 y i32 i32 n return arr x arr y n n n export function testArrayArguments i32 n const arr i32 24 n arr 0 2 n arr 4 3 n return addArray arr 0 4 n n t throws function return 0 _ compile function test return y\\n']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tokenized functions that did not contain docstrigns\n",
    "no_docstring_funcs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:...tokenizing data\n",
      "WARNING:root:...indexing data\n",
      "WARNING:root:...padding data\n"
     ]
    }
   ],
   "source": [
    "encinp = enc_pp.transform_parallel(total_funcs)\n",
    "np.save(code2emb_path/'total_funcs.npy', encinp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract code vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "code2emb_path = Path('./data/code2emb/')\n",
    "encinp = np.load(code2emb_path/'total_funcs.npy')\n",
    "code2emb_model = load_model(code2emb_path/'code2emb_model.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `code2emb` model to map the code into the same vector space as natural language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = code2emb_model.predict(encinp, batch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure the number of output rows equal the number of input rows\n",
    "assert nodoc_vecs.shape[0] == encinp.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the vectorized code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(code2emb_path/'vecs.npy', nodoc_vecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cached Files\n",
    "\n",
    "You can find the files that were created in this notebook below.  **Please note that if you use one of these files, you should proceed with extreme caution.**  We recommend that if you are skipping a step, you should use *all* the cached files because only using only some files could result in discrepencies between your models or data and our pre-computed results.\n",
    "\n",
    "1. `code2emb_model.hdf5`:https://storage.googleapis.com/kubeflow-examples/code_search/data/code2emb/code2emb_model.hdf5\n",
    "2. `nodoc_encinp.npy`:https://storage.googleapis.com/kubeflow-examples/code_search/data/code2emb/nodoc_encinp.npy\n",
    "3. `nodoc_vecs.npy`:https://storage.googleapis.com/kubeflow-examples/code_search/data/code2emb/nodoc_vecs.npy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
