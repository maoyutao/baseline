{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "This notebook contains materials to parse raw python files into function and docstring pairs, tokenize both function and dosctring into tokens, and split these pairs into a train, valid and test set.  \n",
    "\n",
    "*This step is optional, as we provide links to download pre-processed data at various points in the tutorial.  However, you might find it useful to go through these steps in order to understand how the data is prepared.*\n",
    "\n",
    "If you are using the recommended approach of using a `p3.8xlarge` instance for this entire tutorial you can use this docker container to run this notebook: [hamelsmu/ml-gpu](https://hub.docker.com/r/hamelsmu/ml-gpu/).\n",
    "\n",
    "Alternatively, if you wish to speed up *this notebook* by using an instance with lots of cores (because everything in this notebook is CPU bound), you can use this container [hamelsmu/ml-cpu](https://hub.docker.com/r/hamelsmu/ml-gpu/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import re\n",
    "import astor\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from general_utils import apply_parallel, flattenlist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 2.7.15+\r\n"
     ]
    }
   ],
   "source": [
    "! python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and read  raw python files\n",
    "\n",
    "The first thing we will want to do is to gather python code.  There is an open dataset that Google hosts on [BigQuery](https://cloud.google.com/bigquery/) that has code from open source projects on Github.  You can use [bigquery](https://cloud.google.com/bigquery/) to get the python files as a tabular dataset by executing the following SQL query in the bigquery console:\n",
    "\n",
    "```{sql}\n",
    "SELECT \n",
    " max(concat(f.repo_name, ' ', f.path)) as repo_path,\n",
    " c.content\n",
    "FROM `bigquery-public-data.github_repos.files` as f\n",
    "JOIN `bigquery-public-data.github_repos.contents` as c on f.id = c.id\n",
    "JOIN (\n",
    "      --this part of the query makes sure repo is watched at least twice since 2017\n",
    "      SELECT repo FROM(\n",
    "        SELECT \n",
    "          repo.name as repo\n",
    "        FROM `githubarchive.year.2017` WHERE type=\"WatchEvent\"\n",
    "        UNION ALL\n",
    "        SELECT \n",
    "          repo.name as repo\n",
    "        FROM `githubarchive.month.2018*` WHERE type=\"WatchEvent\"\n",
    "        )\n",
    "      GROUP BY 1\n",
    "      HAVING COUNT(*) >= 2\n",
    "      ) as r on f.repo_name = r.repo\n",
    "WHERE \n",
    "  f.path like '%.py' and --with python extension\n",
    "  c.size < 15000 and --get rid of ridiculously long files\n",
    "  REGEXP_CONTAINS(c.content, r'def ') --contains function definition\n",
    "group by c.content\n",
    "```\n",
    "\n",
    "\n",
    "Here is a link to the [SQL Query](https://bigquery.cloud.google.com/savedquery/506213277345:009fa66f301240e5ad9e4006c59a4762) incase it is helpful.  The raw data contains approximate 1.2 million distinct python code files.\n",
    "\n",
    "**To make things easier for this tutorial, the folks on the Google [Kubeflow team](https://kubernetes.io/blog/2017/12/introducing-kubeflow-composable/) have hosted the raw data for this tutorial in the form of 10 csv files, available at the url: https://storage.googleapis.com/kubeflow-examples/code_search/raw_data/00000000000{i}.csv as illustrated in the below code:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nwo</th>\n",
       "      <th>path</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/models.py</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Core models.\"\"\"\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/utils.py</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Utility function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/password_hashers/base.py</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"\\nBase password ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/mocks.py</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Mocks used for t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/views/base.py</td>\n",
       "      <td># -*- coding: utf-8 -*-\\n\\n\"\"\"Base core views....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nwo                                   path  \\\n",
       "0  modoboa                 modoboa/core/models.py   \n",
       "1  modoboa                  modoboa/core/utils.py   \n",
       "2  modoboa  modoboa/core/password_hashers/base.py   \n",
       "3  modoboa                  modoboa/core/mocks.py   \n",
       "4  modoboa             modoboa/core/views/base.py   \n",
       "\n",
       "                                             content  \n",
       "0  # -*- coding: utf-8 -*-\\n\\n\"\"\"Core models.\"\"\"\\...  \n",
       "1  # -*- coding: utf-8 -*-\\n\\n\"\"\"Utility function...  \n",
       "2  # -*- coding: utf-8 -*-\\n\\n\"\"\"\\nBase password ...  \n",
       "3  # -*- coding: utf-8 -*-\\n\\n\"\"\"Mocks used for t...  \n",
       "4  # -*- coding: utf-8 -*-\\n\\n\"\"\"Base core views....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data into a pandas dataframe, and parse out some meta-data\n",
    "\n",
    "# df = pd.read_pickle('py0.pkl')\n",
    "df = pd.concat([pd.read_pickle(f'../py{i}.pkl') for i in range (5)])\n",
    "# df = pd.read_csv(f'01.csv')\n",
    "\n",
    "df['nwo'] = df['repo_path'].apply(lambda r: r.split()[0])\n",
    "df['path'] = df['repo_path'].apply(lambda r: r.split()[-1])\n",
    "df.drop(columns=['repo_path'], inplace=True)\n",
    "df = df[['nwo', 'path', 'content']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181175, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect shape of the raw data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to parse data and tokenize\n",
    "\n",
    "Our goal is to parse the python files into (code, docstring) pairs.  Fortunately, the standard library in python comes with the wonderful [ast](https://docs.python.org/3.6/library/ast.html) module which helps us extract code from files as well as extract docstrings.  \n",
    "\n",
    "We also use the [astor](http://astor.readthedocs.io/en/latest/) library to strip the code of comments by doing a round trip of converting the code to an [AST](https://en.wikipedia.org/wiki/Abstract_syntax_tree) and then from AST back to code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "EN = spacy.load('en')\n",
    "stop_words =  [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"ain\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"aren\", \"aren't\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"can\", \"couldn\", \"couldn't\", \"d\", \"did\", \"didn\", \"didn't\", \"do\", \"does\", \"doesn\", \"doesn't\", \"doing\", \"don\", \"don't\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"hadn\", \"hadn't\", \"has\", \"hasn\", \"hasn't\", \"have\", \"haven\", \"haven't\", \"having\", \"he\", \"her\", \"here\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"i\", \"if\", \"in\", \"into\", \"is\", \"isn\", \"isn't\", \"it\", \"it's\", \"its\", \"itself\", \"just\", \"ll\", \"m\", \"ma\", \"me\", \"mightn\", \"mightn't\", \"more\", \"most\", \"mustn\", \"mustn't\", \"my\", \"myself\", \"needn\", \"needn't\", \"no\", \"nor\", \"not\", \"now\", \"o\", \"of\", \"off\", \"on\", \"once\", \"only\", \"or\", \"other\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"re\", \"s\", \"same\", \"shan\", \"shan't\", \"she\", \"she's\", \"should\", \"should've\", \"shouldn\", \"shouldn't\", \"so\", \"some\", \"such\", \"t\", \"than\", \"that\", \"that'll\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"these\", \"they\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"ve\", \"very\", \"was\", \"wasn\", \"wasn't\", \"we\", \"were\", \"weren\", \"weren't\", \"what\", \"when\", \"where\", \"which\", \"while\", \"who\", \"whom\", \"why\", \"will\", \"with\", \"won\", \"won't\", \"wouldn\", \"wouldn't\", \"y\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\", \"could\", \"he'd\", \"he'll\", \"he's\", \"here's\", \"how's\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"let's\", \"ought\", \"she'd\", \"she'll\", \"that's\", \"there's\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"what's\", \"when's\", \"where's\", \"who's\", \"why's\", \"would\"]\n",
    "for stopword in stop_words:\n",
    "    EN.vocab[stopword].is_stop = True\n",
    "    \n",
    "cop = re.compile(\"[^a-z^0-9]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textacy.preprocess import preprocess_text\n",
    "\n",
    "def tokenize_docstring(text):\n",
    "    \"Apply tokenization using spacy to docstrings.\"\n",
    "    all_tokens = EN.tokenizer(text.lower())\n",
    "    selected_tokens = [cop.sub('', token.text) for token in all_tokens if not token.is_space and not token.is_stop]\n",
    "    return [token for token in selected_tokens if token != '']\n",
    "\n",
    "def tokenize_code(text):\n",
    "    \"A very basic procedure for tokenizing code strings.\"\n",
    "    return RegexpTokenizer(r'\\w+').tokenize(text)\n",
    "\n",
    "\n",
    "def get_function_docstring_pairs(blob):\n",
    "    \"Extract (function/method, docstring) pairs from a given code blob.\"\n",
    "    pairs = []\n",
    "    fc_dict = {}\n",
    "    try:\n",
    "        module = ast.parse(blob)\n",
    "        classes = [node for node in module.body if isinstance(node, ast.ClassDef)]\n",
    "        functions = [node for node in module.body if isinstance(node, ast.FunctionDef)]\n",
    "        for _class in classes:\n",
    "            for node in _class.body:\n",
    "                if isinstance(node, ast.FunctionDef):\n",
    "                    functions.append(node)\n",
    "                    fc_dict[node] = _class.name\n",
    "\n",
    "        for f in functions:\n",
    "            source = astor.to_source(f)\n",
    "            docstring = ast.get_docstring(f) if ast.get_docstring(f) else ''\n",
    "            function = source.replace(ast.get_docstring(f, clean=False), '') if docstring else source\n",
    "            class_name = fc_dict.get(f, '')\n",
    "            pairs.append((class_name + '_' + f.name,\n",
    "                          f.lineno,\n",
    "                          source,\n",
    "                          ' '.join(tokenize_code(function)),\n",
    "                          ' '.join(tokenize_docstring(docstring.split('\\n\\n')[0]))\n",
    "                         ))\n",
    "    except (AssertionError, MemoryError, SyntaxError, UnicodeEncodeError):\n",
    "        pass\n",
    "    return pairs\n",
    "\n",
    "err_content = []\n",
    "def get_function_docstring_pairs_list(blob_list):\n",
    "    \"\"\"apply the function `get_function_docstring_pairs` on a list of blobs\"\"\"\n",
    "    res = []\n",
    "    global err_content\n",
    "    for b in blob_list:\n",
    "        try:\n",
    "            pairs = get_function_docstring_pairs(str(b))\n",
    "            res.append(pairs)\n",
    "        except:\n",
    "            print(b)\n",
    "            err_content.append(b)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "class Seq2Seq_Inference(object):\n",
      "    def __init__(self,\n",
      "                 encoder_preprocessor,\n",
      "                 decoder_preprocessor,\n",
      "                 seq2seq_model):\n",
      "\n",
      "        self.enc_pp = encoder_preprocessor\n",
      "        self.dec_pp = decoder_preprocessor\n",
      "        self.seq2seq_model = seq2seq_model\n",
      "        self.encoder_model = extract_encoder_model(seq2seq_model)\n",
      "        self.decoder_model = extract_decoder_model(seq2seq_model)\n",
      "        self.default_max_len = self.dec_pp.padding_maxlen\n",
      "        self.nn = None\n",
      "        self.rec_df = None\n",
      "    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Seq2Seq_Inference___init__',\n",
       "  4,\n",
       "  'def __init__(self, encoder_preprocessor, decoder_preprocessor, seq2seq_model):\\n    self.enc_pp = encoder_preprocessor\\n    self.dec_pp = decoder_preprocessor\\n    self.seq2seq_model = seq2seq_model\\n    self.encoder_model = extract_encoder_model(seq2seq_model)\\n    self.decoder_model = extract_decoder_model(seq2seq_model)\\n    self.default_max_len = self.dec_pp.padding_maxlen\\n    self.nn = None\\n    self.rec_df = None\\n',\n",
       "  'def __init__ self encoder_preprocessor decoder_preprocessor seq2seq_model self enc_pp encoder_preprocessor self dec_pp decoder_preprocessor self seq2seq_model seq2seq_model self encoder_model extract_encoder_model seq2seq_model self decoder_model extract_decoder_model seq2seq_model self default_max_len self dec_pp padding_maxlen self nn None self rec_df None',\n",
       "  '')]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob = '''\n",
    "\n",
    "class Seq2Seq_Inference(object):\n",
    "    def __init__(self,\n",
    "                 encoder_preprocessor,\n",
    "                 decoder_preprocessor,\n",
    "                 seq2seq_model):\n",
    "\n",
    "        self.enc_pp = encoder_preprocessor\n",
    "        self.dec_pp = decoder_preprocessor\n",
    "        self.seq2seq_model = seq2seq_model\n",
    "        self.encoder_model = extract_encoder_model(seq2seq_model)\n",
    "        self.decoder_model = extract_decoder_model(seq2seq_model)\n",
    "        self.default_max_len = self.dec_pp.padding_maxlen\n",
    "        self.nn = None\n",
    "        self.rec_df = None\n",
    "    '''\n",
    "print(blob)\n",
    "get_function_docstring_pairs(blob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below convience function `apply_parallel` parses the code in parallel using process based threading.  Adjust the `cpu_cores` parameter accordingly to your system resources!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df.head())\n",
    "# pairs = flattenlist(apply_parallel(get_function_docstring_pairs_list, df.content.tolist(), cpu_cores=4))\n",
    "pairs = get_function_docstring_pairs_list(df.content.tolist())\n",
    "df =df[~df['content'].isin(err_content)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(err_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181175, 4)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(pairs) == df.shape[0], f'Row count mismatch. `df` has {df.shape[0]:,} rows; `pairs` has {len(pairs):,} rows.'\n",
    "df['pairs'] = pairs\n",
    "df.to_pickle('temp3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(populate_callback, 393, def populate_callbac...\n",
       "1    [(parse_map_file, 16, def parse_map_file(path)...\n",
       "2    [(name, 28, @property\\ndef name(cls):\\n    \"\"\"...\n",
       "3    [(modo_api_instance_search, 12, @httmock.urlma...\n",
       "4    [(find_nextlocation, 15, def find_nextlocation...\n",
       "Name: pairs, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('temp.pkl')\n",
    "df.head()\n",
    "df['pairs'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flatten code, docstring pairs and extract meta-data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flatten (code, docstring) pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten pairs\n",
    "df = df.set_index(['nwo', 'path'])['pairs'].apply(pd.Series).stack()\n",
    "df = df.reset_index()\n",
    "df.columns = ['nwo', 'path', '_', 'pair']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract meta-data and format dataframe.  \n",
    "\n",
    "We have not optimized this code.  Pull requests are welcome!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['function_name'] = df['pair'].apply(lambda p: p[0])\n",
    "df['lineno'] = df['pair'].apply(lambda p: p[1])\n",
    "df['original_function'] = df['pair'].apply(lambda p: p[2])\n",
    "df['function_tokens'] = df['pair'].apply(lambda p: p[3])\n",
    "df['docstring_tokens'] = df['pair'].apply(lambda p: p[4])\n",
    "df = df[['nwo', 'path', 'function_name', 'lineno', 'original_function', 'function_tokens', 'docstring_tokens']]\n",
    "df['url'] = df[['nwo', 'path', 'lineno']].apply(lambda x: 'https://github.com/{}/blob/master/{}#L{}'.format(x[0], x[1], x[2]), axis=1)\n",
    "df.head()\n",
    "df.to_pickle('total3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nwo</th>\n",
       "      <th>path</th>\n",
       "      <th>function_name</th>\n",
       "      <th>lineno</th>\n",
       "      <th>original_function</th>\n",
       "      <th>function_tokens</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/models.py</td>\n",
       "      <td>populate_callback</td>\n",
       "      <td>393</td>\n",
       "      <td>def populate_callback(user, group='SimpleUsers...</td>\n",
       "      <td>def populate_callback user group SimpleUsers f...</td>\n",
       "      <td>populate callback</td>\n",
       "      <td>https://github.com/modoboa/blob/master/modoboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/models.py</td>\n",
       "      <td>__init__</td>\n",
       "      <td>89</td>\n",
       "      <td>def __init__(self, *args, **kwargs):\\n    \"\"\"L...</td>\n",
       "      <td>def __init__ self args kwargs super User self ...</td>\n",
       "      <td>load parameter manager</td>\n",
       "      <td>https://github.com/modoboa/blob/master/modoboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/models.py</td>\n",
       "      <td>_crypt_password</td>\n",
       "      <td>94</td>\n",
       "      <td>def _crypt_password(self, raw_value):\\n    \"\"\"...</td>\n",
       "      <td>def _crypt_password self raw_value scheme para...</td>\n",
       "      <td>crypt local password appropriate scheme</td>\n",
       "      <td>https://github.com/modoboa/blob/master/modoboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/models.py</td>\n",
       "      <td>set_password</td>\n",
       "      <td>112</td>\n",
       "      <td>def set_password(self, raw_value, curvalue=Non...</td>\n",
       "      <td>def set_password self raw_value curvalue None ...</td>\n",
       "      <td>password update</td>\n",
       "      <td>https://github.com/modoboa/blob/master/modoboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/models.py</td>\n",
       "      <td>check_password</td>\n",
       "      <td>137</td>\n",
       "      <td>def check_password(self, raw_value):\\n    \"\"\"C...</td>\n",
       "      <td>def check_password self raw_value match self p...</td>\n",
       "      <td>compare rawvalue current password</td>\n",
       "      <td>https://github.com/modoboa/blob/master/modoboa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nwo                    path      function_name  lineno  \\\n",
       "0  modoboa  modoboa/core/models.py  populate_callback     393   \n",
       "1  modoboa  modoboa/core/models.py           __init__      89   \n",
       "2  modoboa  modoboa/core/models.py    _crypt_password      94   \n",
       "3  modoboa  modoboa/core/models.py       set_password     112   \n",
       "4  modoboa  modoboa/core/models.py     check_password     137   \n",
       "\n",
       "                                   original_function  \\\n",
       "0  def populate_callback(user, group='SimpleUsers...   \n",
       "1  def __init__(self, *args, **kwargs):\\n    \"\"\"L...   \n",
       "2  def _crypt_password(self, raw_value):\\n    \"\"\"...   \n",
       "3  def set_password(self, raw_value, curvalue=Non...   \n",
       "4  def check_password(self, raw_value):\\n    \"\"\"C...   \n",
       "\n",
       "                                     function_tokens  \\\n",
       "0  def populate_callback user group SimpleUsers f...   \n",
       "1  def __init__ self args kwargs super User self ...   \n",
       "2  def _crypt_password self raw_value scheme para...   \n",
       "3  def set_password self raw_value curvalue None ...   \n",
       "4  def check_password self raw_value match self p...   \n",
       "\n",
       "                          docstring_tokens  \\\n",
       "0                        populate callback   \n",
       "1                   load parameter manager   \n",
       "2  crypt local password appropriate scheme   \n",
       "3                          password update   \n",
       "4        compare rawvalue current password   \n",
       "\n",
       "                                                 url  \n",
       "0  https://github.com/modoboa/blob/master/modoboa...  \n",
       "1  https://github.com/modoboa/blob/master/modoboa...  \n",
       "2  https://github.com/modoboa/blob/master/modoboa...  \n",
       "3  https://github.com/modoboa/blob/master/modoboa...  \n",
       "4  https://github.com/modoboa/blob/master/modoboa...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 284,904 duplicate rows\n"
     ]
    }
   ],
   "source": [
    "# remove observations where the same function appears more than once\n",
    "before_dedup = len(df)\n",
    "df = df.drop_duplicates(['original_function', 'function_tokens'])\n",
    "after_dedup = len(df)\n",
    "\n",
    "print(f'Removed {before_dedup - after_dedup:,} duplicate rows')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1345732, 8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listlen(x):\n",
    "    if not isinstance(x, list):\n",
    "        return 0\n",
    "    return len(x)\n",
    "\n",
    "# functions should not be too long\n",
    "df = df[df.function_tokens.str.split().apply(listlen) <= 500]\n",
    "df.to_pickle('lessthan500_3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1340176, 8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nwo</th>\n",
       "      <th>path</th>\n",
       "      <th>function_name</th>\n",
       "      <th>lineno</th>\n",
       "      <th>original_function</th>\n",
       "      <th>function_tokens</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/models.py</td>\n",
       "      <td>_populate_callback</td>\n",
       "      <td>393</td>\n",
       "      <td>def populate_callback(user, group='SimpleUsers...</td>\n",
       "      <td>def populate_callback user group SimpleUsers f...</td>\n",
       "      <td>populate callback</td>\n",
       "      <td>https://github.com/modoboa/blob/master/modoboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/models.py</td>\n",
       "      <td>User___init__</td>\n",
       "      <td>89</td>\n",
       "      <td>def __init__(self, *args, **kwargs):\\n    \"\"\"L...</td>\n",
       "      <td>def __init__ self args kwargs super User self ...</td>\n",
       "      <td>load parameter manager</td>\n",
       "      <td>https://github.com/modoboa/blob/master/modoboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/models.py</td>\n",
       "      <td>User__crypt_password</td>\n",
       "      <td>94</td>\n",
       "      <td>def _crypt_password(self, raw_value):\\n    \"\"\"...</td>\n",
       "      <td>def _crypt_password self raw_value scheme para...</td>\n",
       "      <td>crypt local password appropriate scheme</td>\n",
       "      <td>https://github.com/modoboa/blob/master/modoboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/models.py</td>\n",
       "      <td>User_set_password</td>\n",
       "      <td>112</td>\n",
       "      <td>def set_password(self, raw_value, curvalue=Non...</td>\n",
       "      <td>def set_password self raw_value curvalue None ...</td>\n",
       "      <td>password update</td>\n",
       "      <td>https://github.com/modoboa/blob/master/modoboa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>modoboa</td>\n",
       "      <td>modoboa/core/models.py</td>\n",
       "      <td>User_check_password</td>\n",
       "      <td>137</td>\n",
       "      <td>def check_password(self, raw_value):\\n    \"\"\"C...</td>\n",
       "      <td>def check_password self raw_value match self p...</td>\n",
       "      <td>compare rawvalue current password</td>\n",
       "      <td>https://github.com/modoboa/blob/master/modoboa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       nwo                    path         function_name  lineno  \\\n",
       "0  modoboa  modoboa/core/models.py    _populate_callback     393   \n",
       "1  modoboa  modoboa/core/models.py         User___init__      89   \n",
       "2  modoboa  modoboa/core/models.py  User__crypt_password      94   \n",
       "3  modoboa  modoboa/core/models.py     User_set_password     112   \n",
       "4  modoboa  modoboa/core/models.py   User_check_password     137   \n",
       "\n",
       "                                   original_function  \\\n",
       "0  def populate_callback(user, group='SimpleUsers...   \n",
       "1  def __init__(self, *args, **kwargs):\\n    \"\"\"L...   \n",
       "2  def _crypt_password(self, raw_value):\\n    \"\"\"...   \n",
       "3  def set_password(self, raw_value, curvalue=Non...   \n",
       "4  def check_password(self, raw_value):\\n    \"\"\"C...   \n",
       "\n",
       "                                     function_tokens  \\\n",
       "0  def populate_callback user group SimpleUsers f...   \n",
       "1  def __init__ self args kwargs super User self ...   \n",
       "2  def _crypt_password self raw_value scheme para...   \n",
       "3  def set_password self raw_value curvalue None ...   \n",
       "4  def check_password self raw_value match self p...   \n",
       "\n",
       "                          docstring_tokens  \\\n",
       "0                        populate callback   \n",
       "1                   load parameter manager   \n",
       "2  crypt local password appropriate scheme   \n",
       "3                          password update   \n",
       "4        compare rawvalue current password   \n",
       "\n",
       "                                                 url  \n",
       "0  https://github.com/modoboa/blob/master/modoboa...  \n",
       "1  https://github.com/modoboa/blob/master/modoboa...  \n",
       "2  https://github.com/modoboa/blob/master/modoboa...  \n",
       "3  https://github.com/modoboa/blob/master/modoboa...  \n",
       "4  https://github.com/modoboa/blob/master/modoboa...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate function w/o docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate functions w/o docstrings\n",
    "# docstrings should be at least 3 words in the docstring to be considered a valid docstring\n",
    "\n",
    "with_docstrings = df[df.docstring_tokens.str.split().apply(listlen) >= 3]\n",
    "with_docstrings.to_pickle('withdoc3.pkl')\n",
    "without_docstrings = df[df.docstring_tokens.str.split().apply(listlen) < 3]\n",
    "without_docstrings.to_pickle('withoutdoc3.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373272, 8)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_docstrings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytmao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "with_docstrings['full_path'] = with_docstrings.apply(lambda row: '/'.join([row['nwo'], row['path'].replace('.', '_'), row['function_name']]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytmao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "without_docstrings['full_path'] = without_docstrings.apply(lambda row: '/'.join([row['nwo'], row['path'].replace('.', '_'), row['function_name']]),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373272, 9)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_docstrings.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partition code by repository to minimize leakage between train, valid & test sets. \n",
    "Rough assumption that each repository has its own style.  We want to avoid having code from the same repository in the training set as well as the validation or holdout set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = with_docstrings.groupby('nwo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, valid, test splits\n",
    "train, test = train_test_split(list(grouped), train_size=0.87, shuffle=True, random_state=8081)\n",
    "train, valid = train_test_split(train, train_size=0.82, random_state=8081)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([d for _, d in train]).reset_index(drop=True)\n",
    "valid = pd.concat([d for _, d in valid]).reset_index(drop=True)\n",
    "test = pd.concat([d for _, d in test]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train set num rows 263,327\n",
      "valid set num rows 59,026\n",
      "test set num rows 50,919\n",
      "without docstring rows 966,904\n"
     ]
    }
   ],
   "source": [
    "print(f'train set num rows {train.shape[0]:,}')\n",
    "print(f'valid set num rows {valid.shape[0]:,}')\n",
    "print(f'test set num rows {test.shape[0]:,}')\n",
    "print(f'without docstring rows {without_docstrings.shape[0]:,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_pickle('train3.pkl')\n",
    "valid.to_pickle('valid3.pkl')\n",
    "test.to_pickle('test3.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preview what the training set looks like.  You can start to see how the data looks, the function tokens and docstring tokens are what will be fed downstream into the models.  The other information is important for diagnostics and bookeeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nwo</th>\n",
       "      <th>path</th>\n",
       "      <th>function_name</th>\n",
       "      <th>lineno</th>\n",
       "      <th>original_function</th>\n",
       "      <th>function_tokens</th>\n",
       "      <th>docstring_tokens</th>\n",
       "      <th>url</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TextRank4ZH</td>\n",
       "      <td>textrank4zh/TextRank4Keyword.py</td>\n",
       "      <td>TextRank4Keyword___init__</td>\n",
       "      <td>18</td>\n",
       "      <td>def __init__(self, stop_words_file=None, allow...</td>\n",
       "      <td>def __init__ self stop_words_file None allow_s...</td>\n",
       "      <td>keyword arguments stopwordsfile str delimiters...</td>\n",
       "      <td>https://github.com/TextRank4ZH/blob/master/tex...</td>\n",
       "      <td>TextRank4ZH/textrank4zh/TextRank4Keyword_py/Te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TextRank4ZH</td>\n",
       "      <td>textrank4zh/TextRank4Sentence.py</td>\n",
       "      <td>TextRank4Sentence___init__</td>\n",
       "      <td>18</td>\n",
       "      <td>def __init__(self, stop_words_file=None, allow...</td>\n",
       "      <td>def __init__ self stop_words_file None allow_s...</td>\n",
       "      <td>keyword arguments stopwordsfile strstr delimit...</td>\n",
       "      <td>https://github.com/TextRank4ZH/blob/master/tex...</td>\n",
       "      <td>TextRank4ZH/textrank4zh/TextRank4Sentence_py/T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TextRank4ZH</td>\n",
       "      <td>textrank4zh/TextRank4Sentence.py</td>\n",
       "      <td>TextRank4Sentence_analyze</td>\n",
       "      <td>43</td>\n",
       "      <td>def analyze(self, text, lower=False, source='n...</td>\n",
       "      <td>def analyze self text lower False source no_st...</td>\n",
       "      <td>keyword arguments text lower false source word...</td>\n",
       "      <td>https://github.com/TextRank4ZH/blob/master/tex...</td>\n",
       "      <td>TextRank4ZH/textrank4zh/TextRank4Sentence_py/T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TextRank4ZH</td>\n",
       "      <td>textrank4zh/Segmentation.py</td>\n",
       "      <td>WordSegmentation___init__</td>\n",
       "      <td>23</td>\n",
       "      <td>def __init__(self, stop_words_file=None, allow...</td>\n",
       "      <td>def __init__ self stop_words_file None allow_s...</td>\n",
       "      <td>keyword arguments stopwordsfile utf8str allows...</td>\n",
       "      <td>https://github.com/TextRank4ZH/blob/master/tex...</td>\n",
       "      <td>TextRank4ZH/textrank4zh/Segmentation_py/WordSe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TextRank4ZH</td>\n",
       "      <td>textrank4zh/Segmentation.py</td>\n",
       "      <td>SentenceSegmentation___init__</td>\n",
       "      <td>85</td>\n",
       "      <td>def __init__(self, delimiters=util.sentence_de...</td>\n",
       "      <td>def __init__ self delimiters util sentence_del...</td>\n",
       "      <td>keyword arguments delimiters</td>\n",
       "      <td>https://github.com/TextRank4ZH/blob/master/tex...</td>\n",
       "      <td>TextRank4ZH/textrank4zh/Segmentation_py/Senten...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           nwo                              path  \\\n",
       "0  TextRank4ZH   textrank4zh/TextRank4Keyword.py   \n",
       "1  TextRank4ZH  textrank4zh/TextRank4Sentence.py   \n",
       "2  TextRank4ZH  textrank4zh/TextRank4Sentence.py   \n",
       "3  TextRank4ZH       textrank4zh/Segmentation.py   \n",
       "4  TextRank4ZH       textrank4zh/Segmentation.py   \n",
       "\n",
       "                   function_name  lineno  \\\n",
       "0      TextRank4Keyword___init__      18   \n",
       "1     TextRank4Sentence___init__      18   \n",
       "2      TextRank4Sentence_analyze      43   \n",
       "3      WordSegmentation___init__      23   \n",
       "4  SentenceSegmentation___init__      85   \n",
       "\n",
       "                                   original_function  \\\n",
       "0  def __init__(self, stop_words_file=None, allow...   \n",
       "1  def __init__(self, stop_words_file=None, allow...   \n",
       "2  def analyze(self, text, lower=False, source='n...   \n",
       "3  def __init__(self, stop_words_file=None, allow...   \n",
       "4  def __init__(self, delimiters=util.sentence_de...   \n",
       "\n",
       "                                     function_tokens  \\\n",
       "0  def __init__ self stop_words_file None allow_s...   \n",
       "1  def __init__ self stop_words_file None allow_s...   \n",
       "2  def analyze self text lower False source no_st...   \n",
       "3  def __init__ self stop_words_file None allow_s...   \n",
       "4  def __init__ self delimiters util sentence_del...   \n",
       "\n",
       "                                    docstring_tokens  \\\n",
       "0  keyword arguments stopwordsfile str delimiters...   \n",
       "1  keyword arguments stopwordsfile strstr delimit...   \n",
       "2  keyword arguments text lower false source word...   \n",
       "3  keyword arguments stopwordsfile utf8str allows...   \n",
       "4                       keyword arguments delimiters   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://github.com/TextRank4ZH/blob/master/tex...   \n",
       "1  https://github.com/TextRank4ZH/blob/master/tex...   \n",
       "2  https://github.com/TextRank4ZH/blob/master/tex...   \n",
       "3  https://github.com/TextRank4ZH/blob/master/tex...   \n",
       "4  https://github.com/TextRank4ZH/blob/master/tex...   \n",
       "\n",
       "                                           full_path  \n",
       "0  TextRank4ZH/textrank4zh/TextRank4Keyword_py/Te...  \n",
       "1  TextRank4ZH/textrank4zh/TextRank4Sentence_py/T...  \n",
       "2  TextRank4ZH/textrank4zh/TextRank4Sentence_py/T...  \n",
       "3  TextRank4ZH/textrank4zh/Segmentation_py/WordSe...  \n",
       "4  TextRank4ZH/textrank4zh/Segmentation_py/Senten...  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output each set to train/valid/test.function/docstrings/lineage files\n",
    "Original functions are also written to compressed json files. (Raw functions contain `,`, `\\t`, `\\n`, etc., it is less error-prone using json format)\n",
    "\n",
    "`{train,valid,test}.lineage` are files that contain a reference to the original location where the code was retrieved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to(df, filename, path='./data/processed_data/'):\n",
    "    \"Helper function to write processed files to disk.\"\n",
    "    out = Path(path)\n",
    "    out.mkdir(exist_ok=True)\n",
    "    df.function_tokens.to_csv(out/'{}.function'.format(filename), index=False)\n",
    "    df.full_path.to_csv(out/'{}.full_path'.format(filename), index=False)\n",
    "    df.original_function.to_json(out/'{}_original_function.json.gz'.format(filename), orient='values', compression='gzip')\n",
    "    if filename != 'without_docstrings':\n",
    "        df.docstring_tokens.to_csv(out/'{}.docstring'.format(filename), index=False)\n",
    "    df.url.to_csv(out/'{}.lineage'.format(filename), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ytmao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:5: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"\n",
      "/home/ytmao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \n",
      "/home/ytmao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:9: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  if __name__ == '__main__':\n",
      "/home/ytmao/.local/lib/python3.6/site-packages/ipykernel_launcher.py:10: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "# write to output files\n",
    "write_to(train, 'train')\n",
    "write_to(valid, 'valid')\n",
    "write_to(test, 'test')\n",
    "write_to(without_docstrings, 'without_docstrings')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        None\n",
       "1        None\n",
       "2        None\n",
       "3        None\n",
       "4        None\n",
       "5        None\n",
       "6        None\n",
       "7        None\n",
       "8        None\n",
       "9        None\n",
       "10       None\n",
       "11       None\n",
       "12       None\n",
       "13       None\n",
       "14       None\n",
       "15       None\n",
       "16       None\n",
       "17       None\n",
       "18       None\n",
       "19       None\n",
       "20       None\n",
       "21       None\n",
       "22       None\n",
       "23       None\n",
       "24       None\n",
       "25       None\n",
       "26       None\n",
       "27       None\n",
       "28       None\n",
       "29       None\n",
       "         ... \n",
       "50889    None\n",
       "50890    None\n",
       "50891    None\n",
       "50892    None\n",
       "50893    None\n",
       "50894    None\n",
       "50895    None\n",
       "50896    None\n",
       "50897    None\n",
       "50898    None\n",
       "50899    None\n",
       "50900    None\n",
       "50901    None\n",
       "50902    None\n",
       "50903    None\n",
       "50904    None\n",
       "50905    None\n",
       "50906    None\n",
       "50907    None\n",
       "50908    None\n",
       "50909    None\n",
       "50910    None\n",
       "50911    None\n",
       "50912    None\n",
       "50913    None\n",
       "50914    None\n",
       "50915    None\n",
       "50916    None\n",
       "50917    None\n",
       "50918    None\n",
       "Length: 50919, dtype: object"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get astminer input\n",
    "import os\n",
    "def write_functions(prefix):\n",
    "    path = './' + prefix + '/'\n",
    "    def func(row):\n",
    "        os.makedirs(path + '/'.join([row['nwo'], row['path'].replace('.', '_')]), exist_ok=True)\n",
    "        with open(Path(path)/'{}.py'.format(row['full_path']), 'w') as outfile:\n",
    "            outfile.write(row['original_function'])\n",
    "    return func\n",
    "\n",
    "train.apply(write_functions(\"train_functions\"),axis=1)\n",
    "valid.apply(write_functions(\"valid_functions\"),axis=1)\n",
    "test.apply(write_functions(\"test_functions\"),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2.6G\r\n",
      "drwxr-xr-x 2 root root 6.0K May 22 00:59 .\r\n",
      "drwxr-xr-x 9 root root 6.0K May 22 00:53 ..\r\n",
      "-rw-r--r-- 1 root root  13M May 22 00:55 test.docstring\r\n",
      "-rw-r--r-- 1 root root  55M May 22 00:55 test.function\r\n",
      "-rw-r--r-- 1 root root  16M May 22 00:55 test.lineage\r\n",
      "-rw-r--r-- 1 root root  25M May 22 00:55 test_original_function.json.gz\r\n",
      "-rw-r--r-- 1 root root  74M May 22 00:55 train.docstring\r\n",
      "-rw-r--r-- 1 root root 312M May 22 00:53 train.function\r\n",
      "-rw-r--r-- 1 root root  89M May 22 00:55 train.lineage\r\n",
      "-rw-r--r-- 1 root root 140M May 22 00:55 train_original_function.json.gz\r\n",
      "-rw-r--r-- 1 root root  15M May 22 00:55 valid.docstring\r\n",
      "-rw-r--r-- 1 root root  67M May 22 00:55 valid.function\r\n",
      "-rw-r--r-- 1 root root  18M May 22 00:55 valid.lineage\r\n",
      "-rw-r--r-- 1 root root  30M May 22 00:55 valid_original_function.json.gz\r\n",
      "-rw-r--r-- 1 root root 1.1G May 22 00:56 without_docstrings.function\r\n",
      "-rw-r--r-- 1 root root 345M May 22 00:59 without_docstrings.lineage\r\n",
      "-rw-r--r-- 1 root root 357M May 22 00:59 without_docstrings_original_function.json.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls -lah ./data/processed_data2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# get astminer input\n",
    "              \n",
    "# docdf = with_docstrings[['nwo', 'path', 'function_name', 'docstring_tokens']]\n",
    "# docdf['full_path'] = docdf.apply(lambda row: '/'.join([row['nwo'], row['path'].replace('.','_'), row['function_name']]),axis=1)\n",
    "# docdf = docdf[['full_path', 'docstring_tokens']]\n",
    "# docdf.to_csv('ast.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The pre-processed data is also hosted on Google Cloud, at the following URLs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/test.docstring\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/test.function\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/test.lineage\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/test_original_function.json.gz\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/train.docstring\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/train.function\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/train.lineage\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/train_original_function.json.gz\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/valid.docstring\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/valid.function\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/valid.lineage\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/valid_original_function.json.gz\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings.function\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings.lineage\n",
      "https://storage.googleapis.com/kubeflow-examples/code_search/data/without_docstrings_original_function.json.gz\n"
     ]
    }
   ],
   "source": [
    "# # cool trick to send shell command results into a python variable in a jupyter notebook!\n",
    "# files = ! ls ./data/processed_data/ | grep -E '*.function$|*.docstring$|*.lineage$|*_original_function.json.gz$'\n",
    "\n",
    "# # print the urls\n",
    "# urls = [f'https://storage.googleapis.com/kubeflow-examples/code_search/data/{f}' for f in files]\n",
    "# for s in urls:\n",
    "#     print(s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
